# configs/hyperparams.yaml
embedding:
  model: "all-MiniLM-L6-v2"
  batch_size: 32
  dimension: 384

retrieval:
  n_results: 5
  
generation:
  gpt4:
    temperature: 0.3
    max_tokens: 1000
  tiny_llama:
    temperature: 0.7
    top_p: 0.9
    max_length: 512

chunking:
  chunk_size: 512
  chunk_overlap: 100
